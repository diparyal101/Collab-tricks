{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Basic Collab.ipynb",
      "provenance": [],
      "mount_file_id": "1kL61D0vyN-hsPC4_-ASlntXgbbvwKphX",
      "authorship_tag": "ABX9TyNLTt5ILuL/7lpYLanLLAYf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/diparyal101/Collab-tricks/blob/master/Basic_Collab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZcxA3y9Dgix6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dB2nQnshkCv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2af5a8bd-d419-4a0b-b353-1c0fd6ddede2"
      },
      "source": [
        "#list file on Current Directory\n",
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gv-RtrJqjYlP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "073a77ee-9770-4594-e124-50d75eb00bfa"
      },
      "source": [
        "#View Current Directory\n",
        "cd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/root\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrsr_lVIjMRB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Change current Directory\n",
        "\n",
        "cd '/content/drive/My Drive/pytorch'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZgOB9pujwhw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To avoid using full path of Directory\n",
        "\n",
        "import os\n",
        "os.chdir(\"drive/pytorch\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCIltMIDhpA1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e0303546-ce3e-4933-bf90-ea0a10c2ed56"
      },
      "source": [
        "#Run test.py file\n",
        "!python3 \"/content/drive/My Drive/pytorch/test.py\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "drive  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ih5hWLM0h7ow",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Download .csv from url to \"pytorch\" folder\n",
        "\n",
        "!wget https://raw.githubusercontent.com/vincentarelbundock/Rdatasets/master/csv/datasets/Titanic.csv -P \"/content/drive/My Drive/pytorch\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pem5GLSrido7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "titanic = pd.read_csv(“/content/drive/My Drive/app/Titanic.csv”)\n",
        "titanic.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8TxaTSgi6BX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Git clone \n",
        "\n",
        "!git clone https://github.com/wxs/keras-mnist-tutorial.git"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYqxu_zVjAQZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Install Application \n",
        "\n",
        "!pip install -q keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dr9OBE36jEDb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Remove folder\n",
        "\n",
        "!rm -rf folder_name"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r8IdCbDSjlxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Restart collab\n",
        "\n",
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gRdMIRKlkdMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#To view Fuctional argument add question mark\"?\" after function name\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.nn.sigmoid_cross_entropy_with_logits?"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FAK3soSojjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a1fd14d5-e96f-4b59-c0ab-008cad480906"
      },
      "source": [
        "\n",
        "# %tensorflow_version 1.x\n",
        "# import tensorflow\n",
        "# print(tensorflow.__version__)\n",
        "\n",
        "# !wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "# !unzip ngrok-stable-linux-amd64.zip\n",
        "\n",
        "# You can change the directory name\n",
        "LOG_DIR = 'tb_logs'\n",
        "\n",
        "import os\n",
        "if not os.path.exists(LOG_DIR):\n",
        "  os.makedirs(LOG_DIR)\n",
        "  \n",
        "get_ipython().system_raw(\n",
        "    'tensorboard --logdir {} --host 0.0.0.0 --port 6006 &'\n",
        "    .format(LOG_DIR))\n",
        "\n",
        "get_ipython().system_raw('./ngrok http 6006 &')\n",
        "\n",
        "!curl -s http://localhost:4040/api/tunnels | python3 -c \\\n",
        "    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "https://6ed205f8e1fd.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3t_hwlZmcii",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        },
        "outputId": "99c1aaf1-9918-421a-8de0-786714322e44"
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "\n",
        "tbCallBack = TensorBoard(log_dir='./logs', \n",
        "                         histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test),\n",
        "          callbacks=[tbCallBack])\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v2.py:92: UserWarning: The TensorBoard callback `batch_size` argument (for histogram computation) is deprecated with TensorFlow 2.0. It will be ignored.\n",
            "  warnings.warn('The TensorBoard callback `batch_size` argument '\n",
            "/usr/local/lib/python3.6/dist-packages/keras/callbacks/tensorboard_v2.py:97: UserWarning: The TensorBoard callback does not support gradients display when using TensorFlow 2.0. The `write_grads` argument is ignored.\n",
            "  warnings.warn('The TensorBoard callback does not support '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/12\n",
            "60000/60000 [==============================] - 11s 191us/step - loss: 0.2575 - accuracy: 0.9219 - val_loss: 0.0547 - val_accuracy: 0.9820\n",
            "Epoch 2/12\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0855 - accuracy: 0.9753 - val_loss: 0.0380 - val_accuracy: 0.9871\n",
            "Epoch 3/12\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0640 - accuracy: 0.9806 - val_loss: 0.0344 - val_accuracy: 0.9879\n",
            "Epoch 4/12\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0542 - accuracy: 0.9836 - val_loss: 0.0304 - val_accuracy: 0.9897\n",
            "Epoch 5/12\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0460 - accuracy: 0.9856 - val_loss: 0.0297 - val_accuracy: 0.9899\n",
            "Epoch 6/12\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0405 - accuracy: 0.9876 - val_loss: 0.0321 - val_accuracy: 0.9894\n",
            "Epoch 7/12\n",
            "60000/60000 [==============================] - 11s 187us/step - loss: 0.0371 - accuracy: 0.9885 - val_loss: 0.0238 - val_accuracy: 0.9920\n",
            "Epoch 8/12\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0345 - accuracy: 0.9894 - val_loss: 0.0264 - val_accuracy: 0.9908\n",
            "Epoch 9/12\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0313 - accuracy: 0.9907 - val_loss: 0.0261 - val_accuracy: 0.9923\n",
            "Epoch 10/12\n",
            "60000/60000 [==============================] - 11s 188us/step - loss: 0.0298 - accuracy: 0.9911 - val_loss: 0.0265 - val_accuracy: 0.9914\n",
            "Epoch 11/12\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0272 - accuracy: 0.9917 - val_loss: 0.0267 - val_accuracy: 0.9909\n",
            "Epoch 12/12\n",
            "60000/60000 [==============================] - 11s 189us/step - loss: 0.0262 - accuracy: 0.9919 - val_loss: 0.0276 - val_accuracy: 0.9913\n",
            "Test loss: 0.027587456033222043\n",
            "Test accuracy: 0.9912999868392944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IFewAqj0OmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "/content/logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4-GsI820OCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "a5245386-36b8-426e-ecf2-e714bff9bdc2"
      },
      "source": [
        "python -m tensorboard.py --logdir=/content/logs"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-6-9cc5e42d4ad9>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python -m tensorboard.py --logdir=/content/logs\u001b[0m\n\u001b[0m                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlyellEiw9F6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 132
        },
        "outputId": "f293613a-8700-4d50-8064-1f8e87628c0a"
      },
      "source": [
        "%load_ext tensorboard  # only needed once (e.g., at top of notebook)\n",
        "\n",
        "%tensorboard --logdir logs"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-4-d9451e933c5e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    content(/logs)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EttARlfpzywe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}